{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from utilities3 import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Adam import Adam\n",
    "from timeit import default_timer\n",
    "\n",
    "# import local modules from FNO2D.py\n",
    "from FNO2D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "gc = pd.read_csv(\"Data/gc_samples_filtered.csv\", header=None)\n",
    "d = pd.read_csv(\"Data/d_samples_filtered.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in gc:  3207\n"
     ]
    }
   ],
   "source": [
    "# check number of samples in gc\n",
    "print(\"Number of samples in gc: \", len(gc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates data from csv file\n",
    "coordinates = pd.read_csv(\"Data/coordinates_n\", header=None)\n",
    "\n",
    "# output mesh coordinates\n",
    "damage_x = pd.read_csv('Data/x_ver', header=None)\n",
    "damage_y = pd.read_csv('Data/y_ver', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ver shape:  (3918, 1)\n",
      "y_ver shape:  (3918, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_ver shape: \", damage_x.shape)\n",
    "print(\"y_ver shape: \", damage_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate damage_x and damage_y\n",
    "damage_xy = np.concatenate((damage_x, damage_y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gc shape:  (3207, 7610)\n",
      "d shape:  (3207, 3918)\n",
      "coordinates shape:  (7610, 2)\n",
      "damage_xy shape:  (3918, 2)\n"
     ]
    }
   ],
   "source": [
    "#  convert to torch tensor\n",
    "print(\"gc shape: \", gc.shape)\n",
    "print(\"d shape: \", d.shape)\n",
    "print(\"coordinates shape: \", coordinates.shape)\n",
    "print(\"damage_xy shape: \", damage_xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numpy array with shape (len(gc), gc.shape[1], 2)\n",
    "input_mesh = np.zeros((len(gc), gc.shape[1], 2))\n",
    "\n",
    "# for each sample in input_mesh, add the coordinates\n",
    "for i in range(len(gc)):\n",
    "    input_mesh[i, :, :] = coordinates\n",
    "    \n",
    "# add gc to the last dimension of input_mesh to have shape of (len(gc), gc.shape[1], 3)\n",
    "input_data = np.concatenate((input_mesh, np.expand_dims(gc, axis=2)), axis=2)\n",
    "input_data = torch.from_numpy(input_data).float()\n",
    "\n",
    "d = torch.from_numpy(d.values).float()\n",
    "damage_xy = torch.from_numpy(damage_xy).float()\n",
    "input_mesh = torch.from_numpy(input_mesh).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split X data, for use in creating TensorDataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, d, test_size=0.2, random_state=42)\n",
    "\n",
    "batch_size = 32;\n",
    "train_loader = DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for model\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 501\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 12\n",
    "width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO2d(modes, modes, width=width, in_channels=3, out_channels=1).cuda()\n",
    "model_iphi = IPHI(width=width).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1482721 63907\n"
     ]
    }
   ],
   "source": [
    "print(count_params(model), count_params(model_iphi))\n",
    "\n",
    "params = list(model.parameters()) + list(model_iphi.parameters())\n",
    "optimizer = Adam(params, lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2565"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jin Yi/Documents/ArianaPHD/research/neural_operator/neural_operator.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/mnt/c/Users/Jin%20Yi/Documents/ArianaPHD/research/neural_operator/neural_operator.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m samples_x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(batch_size, N_sample, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcuda() \u001b[39m*\u001b[39m \u001b[39m3\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/mnt/c/Users/Jin%20Yi/Documents/ArianaPHD/research/neural_operator/neural_operator.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/mnt/c/Users/Jin%20Yi/Documents/ArianaPHD/research/neural_operator/neural_operator.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m out \u001b[39m=\u001b[39m model(data, iphi\u001b[39m=\u001b[39;49mmodel_iphi, x_in \u001b[39m=\u001b[39;49m input_mesh, x_out \u001b[39m=\u001b[39;49m damage_xy)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/mnt/c/Users/Jin%20Yi/Documents/ArianaPHD/research/neural_operator/neural_operator.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(out\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blocalhost/mnt/c/Users/Jin%20Yi/Documents/ArianaPHD/research/neural_operator/neural_operator.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m samples_xi \u001b[39m=\u001b[39m model_iphi(samples_x)\n",
      "File \u001b[0;32m~/miniconda3/envs/phasefield/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Jin Yi/Documents/ArianaPHD/research/neural_operator/FNO2D.py:201\u001b[0m, in \u001b[0;36mFNO2d.forward\u001b[0;34m(self, u, code, x_in, x_out, iphi)\u001b[0m\n\u001b[1;32m    198\u001b[0m u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc0(u)\n\u001b[1;32m    199\u001b[0m u \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m uc1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv0(u, x_in\u001b[39m=\u001b[39;49mx_in, iphi\u001b[39m=\u001b[39;49miphi, code\u001b[39m=\u001b[39;49mcode)\n\u001b[1;32m    202\u001b[0m uc3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb0(grid)\n\u001b[1;32m    203\u001b[0m uc \u001b[39m=\u001b[39m uc1 \u001b[39m+\u001b[39m uc3\n",
      "File \u001b[0;32m~/miniconda3/envs/phasefield/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Jin Yi/Documents/ArianaPHD/research/neural_operator/FNO2D.py:44\u001b[0m, in \u001b[0;36mSpectralConv2d.forward\u001b[0;34m(self, u, x_in, x_out, iphi, code)\u001b[0m\n\u001b[1;32m     42\u001b[0m     s2 \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     u_ft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfft2d(u, x_in, iphi, code)\n\u001b[1;32m     45\u001b[0m     s1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms1\n\u001b[1;32m     46\u001b[0m     s2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms2\n",
      "File \u001b[0;32m/mnt/c/Users/Jin Yi/Documents/ArianaPHD/research/neural_operator/FNO2D.py:86\u001b[0m, in \u001b[0;36mSpectralConv2d.fft2d\u001b[0;34m(self, u, x_in, iphi, code)\u001b[0m\n\u001b[1;32m     84\u001b[0m     x \u001b[39m=\u001b[39m x_in\n\u001b[1;32m     85\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     x \u001b[39m=\u001b[39m iphi(x_in, code)\n\u001b[1;32m     88\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m# K = <y, k_x>,  (batch, N, m1, m2)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m K1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mouter(x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), k_x1\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mreshape(batchsize, N, m1, m2)\n",
      "File \u001b[0;32m~/miniconda3/envs/phasefield/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Jin Yi/Documents/ArianaPHD/research/neural_operator/FNO2D.py:284\u001b[0m, in \u001b[0;36mIPHI.forward\u001b[0;34m(self, x, code)\u001b[0m\n\u001b[1;32m    282\u001b[0m b, n, d \u001b[39m=\u001b[39m xd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], xd\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], xd\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n\u001b[1;32m    283\u001b[0m x_sin \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB \u001b[39m*\u001b[39m xd\u001b[39m.\u001b[39mview(b,n,d,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mview(b,n,d\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m--> 284\u001b[0m x_cos \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcos(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB \u001b[39m*\u001b[39;49m xd\u001b[39m.\u001b[39;49mview(b,n,d,\u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mview(b,n,d\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m    285\u001b[0m xd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc0(xd)\n\u001b[1;32m    286\u001b[0m xd \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([xd, x_sin, x_cos], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(b,n,\u001b[39m3\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "# clear cuda cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "N_sample = 1000 # number of samples for regularization\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    train_reg = 0\n",
    "    for data, damage in train_loader:\n",
    "        damage, data = damage.cuda(), data.cuda()\n",
    "        input_mesh = input_mesh.cuda()\n",
    "        damage_xy = damage_xy.cuda()\n",
    "        samples_x = torch.rand(batch_size, N_sample, 3).cuda() * 3 -1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, iphi=model_iphi, x_in = input_mesh, x_out = damage_xy)\n",
    "        print(out.shape)\n",
    "        samples_xi = model_iphi(samples_x)\n",
    "\n",
    "        loss_data = myloss(out.view(batch_size, -1), damage.view(batch_size, -1))\n",
    "        loss_reg = myloss(samples_xi, samples_x)\n",
    "        loss = loss_data + 0.000 * loss_reg\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += loss_data.item()\n",
    "        train_reg += loss_reg.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for rr, damage, data in test_loader:\n",
    "            rr, damage, data = rr.cuda(), damage.cuda(), data.cuda()\n",
    "            # out = model(mesh, iphi=model_iphi)\n",
    "            out = model(data, code=rr, iphi=model_iphi)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), damage.view(batch_size, -1)).item()\n",
    "\n",
    "    train_l2 /= X_train.shape[0]\n",
    "    train_reg /= X_train.shape[0]\n",
    "    test_l2 /= X_test.shape[0]\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2 - t1, train_l2, train_reg, test_l2)\n",
    "\n",
    "    if ep%100==0:\n",
    "        XY = data[-1].squeeze().detach().cpu().numpy()\n",
    "        truth = damage[-1].squeeze().detach().cpu().numpy()\n",
    "        pred = out[-1].squeeze().detach().cpu().numpy()\n",
    "\n",
    "        # lims = dict(cmap='RdBu_r', vmin=truth.min(), vmax=truth.max())\n",
    "        # fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "        # ax[0].scatter(XY[:, 0], XY[:, 1], 100, truth, edgecolor='w', lw=0.1, **lims)\n",
    "        # ax[1].scatter(XY[:, 0], XY[:, 1], 100, pred, edgecolor='w', lw=0.1, **lims)\n",
    "        # ax[2].scatter(XY[:, 0], XY[:, 1], 100, truth - pred, edgecolor='w', lw=0.1, **lims)\n",
    "        # fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phasefield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb9419f644557548447ecb0f1119aef2567eb0b9ec92744eeb7ce809f1fc1aa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
